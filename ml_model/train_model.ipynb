{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0e44288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"C:/Users/Anushka/Desktop/anushka/ML/projects_vscode/IPL prediction system\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a04056ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['match_id', 'batting_team', 'innings_total_runs', 'wickets_lost']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data_processing/processed_data/final_features.csv')\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1298470a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   match_id                 batting_team  innings_total_runs  wickets_lost  \\\n",
      "0    335982        Kolkata Knight Riders                 222             3   \n",
      "1    335982  Royal Challengers Bangalore                  82             9   \n",
      "2    335983          Chennai Super Kings                 240             5   \n",
      "3    335983              Kings XI Punjab                 207             4   \n",
      "4    335984             Delhi Daredevils                 132             1   \n",
      "\n",
      "                  winner  \n",
      "0  KOLKATA KNIGHT RIDERS  \n",
      "1  KOLKATA KNIGHT RIDERS  \n",
      "2    CHENNAI SUPER KINGS  \n",
      "3    CHENNAI SUPER KINGS  \n",
      "4       DELHI DAREDEVILS  \n"
     ]
    }
   ],
   "source": [
    "matches_df = pd.read_csv('data_processing/cleaned_matches.csv')\n",
    "\n",
    "matches_df.rename(columns={'id': 'match_id'}, inplace=True)\n",
    "\n",
    "merged_df = pd.merge(df, matches_df[['match_id', 'winner']], on='match_id', how='left')\n",
    "\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe39d820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['match_id', 'batting_team', 'innings_total_runs', 'wickets_lost']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04610fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features columns: ['match_id', 'batting_team', 'innings_total_runs', 'wickets_lost', 'winner']\n",
      "Matches columns: ['id', 'season', 'city', 'date', 'match_type', 'player_of_match', 'venue', 'team1', 'team2', 'toss_winner', 'toss_decision', 'winner', 'result', 'result_margin', 'target_runs', 'target_overs', 'super_over', 'method', 'umpire1', 'umpire2']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "features_df = pd.read_csv('data_processing/processed_data/final_features.csv')\n",
    "matches_df = pd.read_csv('data_processing/cleaned_matches.csv')\n",
    "\n",
    "print(\"Features columns:\", features_df.columns.tolist())\n",
    "print(\"Matches columns:\", matches_df.columns.tolist())\n",
    "\n",
    "matches_df = matches_df.rename(columns={'id': 'match_id'})\n",
    "\n",
    "merged_df = features_df.merge(matches_df[['match_id', 'winner']], on='match_id', how='left')\n",
    "\n",
    "merged_df.to_csv('data_processing/processed_data/final_features.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62b8294d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "695f809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_processing/processed_data/final_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e11ee586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3555045871559633\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.36      0.36        55\n",
      "           1       0.21      0.25      0.23        12\n",
      "           2       0.43      0.42      0.43        24\n",
      "           3       0.48      0.36      0.41        33\n",
      "           4       1.00      0.25      0.40         4\n",
      "           5       0.62      0.31      0.42        16\n",
      "           6       0.27      0.44      0.33        32\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.40      0.27      0.33        62\n",
      "           9       0.20      0.12      0.15         8\n",
      "          10       0.40      0.52      0.45        48\n",
      "          11       0.00      0.00      0.00         5\n",
      "          12       0.10      0.17      0.12         6\n",
      "          13       0.30      0.35      0.32        37\n",
      "          14       1.00      0.17      0.29         6\n",
      "          15       0.00      0.00      0.00         2\n",
      "          16       0.28      0.33      0.30        40\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       0.49      0.42      0.45        45\n",
      "\n",
      "    accuracy                           0.36       436\n",
      "   macro avg       0.34      0.25      0.26       436\n",
      "weighted avg       0.38      0.36      0.36       436\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anushka\\Desktop\\anushka\\ML\\projects_vscode\\IPL prediction system\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Anushka\\Desktop\\anushka\\ML\\projects_vscode\\IPL prediction system\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Anushka\\Desktop\\anushka\\ML\\projects_vscode\\IPL prediction system\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(subset=['winner'])\n",
    "\n",
    "# Encode categorical features\n",
    "df['batting_team'] = df['batting_team'].astype('category').cat.codes\n",
    "df['winner'] = df['winner'].astype('category')\n",
    "df['winner_code'] = df['winner'].cat.codes\n",
    "\n",
    "X = df[['batting_team', 'innings_total_runs', 'wickets_lost']]\n",
    "y = df['winner_code']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5e322a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
