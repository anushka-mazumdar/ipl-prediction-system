{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0e44288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"C:/Users/Anushka/Desktop/anushka/ML/projects_vscode/IPL prediction system\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a04056ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['match_id', 'batting_team', 'innings_total_runs', 'wickets_lost']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data_processing/processed_data/final_features.csv')\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1298470a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   match_id                 batting_team  innings_total_runs  wickets_lost  \\\n",
      "0    335982        Kolkata Knight Riders                 222             3   \n",
      "1    335982  Royal Challengers Bangalore                  82             9   \n",
      "2    335983          Chennai Super Kings                 240             5   \n",
      "3    335983              Kings XI Punjab                 207             4   \n",
      "4    335984             Delhi Daredevils                 132             1   \n",
      "\n",
      "                  winner  \n",
      "0  KOLKATA KNIGHT RIDERS  \n",
      "1  KOLKATA KNIGHT RIDERS  \n",
      "2    CHENNAI SUPER KINGS  \n",
      "3    CHENNAI SUPER KINGS  \n",
      "4       DELHI DAREDEVILS  \n"
     ]
    }
   ],
   "source": [
    "matches_df = pd.read_csv('data_processing/cleaned_matches.csv')\n",
    "\n",
    "matches_df.rename(columns={'id': 'match_id'}, inplace=True)\n",
    "\n",
    "merged_df = pd.merge(df, matches_df[['match_id', 'winner']], on='match_id', how='left')\n",
    "\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe39d820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['match_id', 'batting_team', 'innings_total_runs', 'wickets_lost']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04610fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features columns: ['match_id', 'batting_team', 'innings_total_runs', 'wickets_lost', 'winner', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8']\n",
      "Matches columns: ['id', 'season', 'city', 'date', 'match_type', 'player_of_match', 'venue', 'team1', 'team2', 'toss_winner', 'toss_decision', 'winner', 'result', 'result_margin', 'target_runs', 'target_overs', 'super_over', 'method', 'umpire1', 'umpire2']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "features_df = pd.read_csv('data_processing/processed_data/final_features.csv')\n",
    "matches_df = pd.read_csv('data_processing/cleaned_matches.csv')\n",
    "\n",
    "print(\"Features columns:\", features_df.columns.tolist())\n",
    "print(\"Matches columns:\", matches_df.columns.tolist())\n",
    "\n",
    "matches_df = matches_df.rename(columns={'id': 'match_id'})\n",
    "\n",
    "merged_df = features_df.merge(matches_df[['match_id', 'winner']], on='match_id', how='left')\n",
    "\n",
    "merged_df.to_csv('data_processing/processed_data/final_features.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62b8294d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "695f809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_processing/processed_data/final_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e11ee586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3853211009174312\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.36      0.36        55\n",
      "           1       0.25      0.33      0.29        12\n",
      "           2       0.46      0.46      0.46        24\n",
      "           3       0.54      0.39      0.46        33\n",
      "           4       0.67      0.50      0.57         4\n",
      "           5       0.56      0.31      0.40        16\n",
      "           6       0.27      0.38      0.31        32\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.46      0.27      0.34        62\n",
      "           9       0.29      0.25      0.27         8\n",
      "          10       0.44      0.56      0.49        48\n",
      "          11       0.20      0.20      0.20         5\n",
      "          12       0.09      0.17      0.12         6\n",
      "          13       0.33      0.35      0.34        37\n",
      "          14       0.80      0.67      0.73         6\n",
      "          15       0.50      0.50      0.50         2\n",
      "          16       0.32      0.33      0.32        40\n",
      "          17       0.33      1.00      0.50         1\n",
      "          18       0.49      0.47      0.48        45\n",
      "\n",
      "    accuracy                           0.39       436\n",
      "   macro avg       0.39      0.39      0.38       436\n",
      "weighted avg       0.41      0.39      0.39       436\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anushka\\Desktop\\anushka\\ML\\projects_vscode\\IPL prediction system\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Anushka\\Desktop\\anushka\\ML\\projects_vscode\\IPL prediction system\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Anushka\\Desktop\\anushka\\ML\\projects_vscode\\IPL prediction system\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ml_model/random_forest_model.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('data_processing/processed_data/final_features.csv')\n",
    "\n",
    "# Drop rows where target is missing\n",
    "df = df.dropna(subset=['winner'])\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=['winner', 'match_id'])  # Drop match_id if not predictive\n",
    "y = df['winner']\n",
    "\n",
    "# Encode categorical features\n",
    "X = pd.get_dummies(X)         # one-hot encoding for features\n",
    "y = y.astype('category').cat.codes  # encode winner labels numerically\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Save model\n",
    "joblib.dump(model, 'ml_model/random_forest_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5e322a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
